{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a58d3383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chapter 6:\n",
    "# Data Encoding and Processing\n",
    "\n",
    "# Learn to read and analyze common file encodings, including:\n",
    "# CSV files\n",
    "# JSON\n",
    "# XML\n",
    "# binary packed records\n",
    "\n",
    "# getting data in and out of a program\n",
    "\n",
    "# 6.1\n",
    "# Read and Write CSV Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3256be66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read or write data encoded as a CSV file\n",
    "\n",
    "# USE the csv library\n",
    "import csv\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        # Process row\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac908a2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Type names and field names must be valid identifiers: ' Symbol'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m f_csv \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mreader(f)\n\u001b[1;32m     20\u001b[0m headings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(f_csv)\n\u001b[0;32m---> 21\u001b[0m Row \u001b[38;5;241m=\u001b[39m \u001b[43mnamedtuple\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheadings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m f_csv:\n\u001b[1;32m     23\u001b[0m     row \u001b[38;5;241m=\u001b[39m Row(\u001b[38;5;241m*\u001b[39mr)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/collections/__init__.py:390\u001b[0m, in \u001b[0;36mnamedtuple\u001b[0;34m(typename, field_names, rename, defaults, module)\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType names and field names must be strings\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name\u001b[38;5;241m.\u001b[39misidentifier():\n\u001b[0;32m--> 390\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType names and field names must be valid \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    391\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124midentifiers: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _iskeyword(name):\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType names and field names cannot be a \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    394\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeyword: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Type names and field names must be valid identifiers: ' Symbol'"
     ]
    }
   ],
   "source": [
    "# \"row\" in the code body of the loop 'for row in f_csv'\n",
    "# will be a tuple.\n",
    "# Thus, to access certain fields use indexing such as:\n",
    "\n",
    "\n",
    "# row[0]('Symbol')\n",
    "# row[4]('Change')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# USE NAMED TUPLED during open():\n",
    "\n",
    "# Since blind indexing may get confusing, a named tuple might\n",
    "# be put to good use here:\n",
    "\n",
    "from collections import namedtuple\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headings = next(f_csv)\n",
    "    Row = namedtuple('Row', headings)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "        # Process row\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b2fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now with a namedtuple for each line of stock data,\n",
    "# these can be accessed using column headers such as:\n",
    "row.Symbol\n",
    "row.Change\n",
    "# instead of using just indeces\n",
    "# THIS WILL ONLY WORK if the column headers are valid\n",
    "# Python identifiers.\n",
    "# If not valid identifiers, will need to finesse initial\n",
    "# headings like replacing nonidentifier chars with underscores\n",
    "# or some such"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82936079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another option\n",
    "# READ the data as a SEQUENCE OF DICTIONARIES instead\n",
    "\n",
    "import csv\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.DictReader(f)\n",
    "    for row in f_csv:\n",
    "        # process row\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d64999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the above snippet, access element of each row using\n",
    "# row headers, like row['Symbol'] or row['Change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a6ae0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing with CSV data\n",
    "# use the csv module but create a writer object\n",
    "\n",
    "headers = ['Symbol','Price','Date','Time','Change','Volume']\n",
    "rows = [('AA', 39.48, '6/11/2007', '9:36am', -0.18, 181800),\n",
    "       ('AIG', 71.38, '6/11/2007', '9:36am', -0.15, 195500),\n",
    "       ('AXP', 62,58, '6/11/2007', '9:36am', -0.46, 935000)\n",
    "       ]\n",
    "\n",
    "with open('stocks.csv','w') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerow(headers)\n",
    "    f_csv.writerows(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e31688bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m f_csv \u001b[38;5;241m=\u001b[39m csv\u001b[38;5;241m.\u001b[39mDictWriter(f, headers)\n\u001b[1;32m      9\u001b[0m f_csv\u001b[38;5;241m.\u001b[39mwriteheader()\n\u001b[0;32m---> 10\u001b[0m \u001b[43mf_csv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/csv.py:157\u001b[0m, in \u001b[0;36mDictWriter.writerows\u001b[0;34m(self, rowdicts)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwriterows\u001b[39m(\u001b[38;5;28mself\u001b[39m, rowdicts):\n\u001b[0;32m--> 157\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriterows\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dict_to_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowdicts\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/csv.py:147\u001b[0m, in \u001b[0;36mDictWriter._dict_to_list\u001b[0;34m(self, rowdict)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_dict_to_list\u001b[39m(\u001b[38;5;28mself\u001b[39m, rowdict):\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextrasaction \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 147\u001b[0m         wrong_fields \u001b[38;5;241m=\u001b[39m \u001b[43mrowdict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfieldnames\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m wrong_fields:\n\u001b[1;32m    149\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdict contains fields not in fieldnames: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m                              \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mrepr\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m wrong_fields]))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "# If the data are a sequence of dictionaries, do:\n",
    "headers = ['Symbol','Price','Date', 'Time', 'Change', 'Volume']\n",
    "rows = [{'Symbol':'AA', 'Price':39.48, 'Date':'6/11/2007','Time':'9:36am','Change':-0.18,'Volume':181800},\n",
    "       {'Symbol':'AIG', 'Price': 71.38, 'Date': '6/11/2007', 'Time':'9:36am', 'Change': -0.15,'Volume': 195500}]\n",
    "        # and so on...\n",
    "    \n",
    "with open('stocks.csv','w') as f:\n",
    "    f_csv = csv.DictWriter(f, headers)\n",
    "    f_csv.writeheader()\n",
    "    f_csv.writerows(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ace231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generally tis better to use the csv module over manually\n",
    "# splitting and parsing CSV data myself. Watch out for code like:\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    for line in f:\n",
    "        row = line.split(',')\n",
    "        # process row\n",
    "        # ...\n",
    "\n",
    "# PROBLEMS HERE:\n",
    "# need to deal with nasty details. Examples:\n",
    "# if any fields are surrounded in quotes, must strip quotes!\n",
    "# plus, if a quoted field happens to include a comma, the code\n",
    "# will break by producing a row with the wrong size!\n",
    "\n",
    "# csv by default understands CSV encoding rules used by\n",
    "# Microsoft Excel, the most common variant.\n",
    "# the docs for csv demonstrate a couple tweaks for encoding\n",
    "# in other formats\n",
    "\n",
    "# what if data is tab-delimited?\n",
    "\n",
    "# with open('stock.tsv') as f:\n",
    "#     f_tsv = csv.reader(f, delimiter='\\t')\n",
    "#     for row in f_tsv:\n",
    "#         # Process row\n",
    "#         # ...\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4b87695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume\\n']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7773f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Named TUPLES again\n",
    "\n",
    "# Careful for validating column headers\n",
    "\n",
    "# some nonvalid identifier characters in a header might be:\n",
    "\n",
    "# Street Address,Num-Premises,Latitude,Longitude\n",
    "# 5412 N CLARK,10,41.980262, -87.668452\n",
    "\n",
    "# ValueError will get throw when the parser tries to create a\n",
    "# namedTuple. Can try scrubbing the headers first?\n",
    "# Write in some regex substitution on nonvalid identifier characters\n",
    "# like this example:\n",
    "\n",
    "import re\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = [ re.sub('[^a-zA-Z_]', '_', h) for h in next(f_csv) ]\n",
    "    Row = namedtuple('Row', headers)\n",
    "    for r in f_csv:\n",
    "        row = Row(*r)\n",
    "        # process row\n",
    "        # ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f266e626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume\\n']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e644fa8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading as dicts with type conversion\n"
     ]
    }
   ],
   "source": [
    "# CSV DOES NOT try to interpret the data or convert it to a type\n",
    "# other than a string.\n",
    "# If these conversions are important, I have to do it myself\n",
    "\n",
    "# Example: extra type conversions on csv data\n",
    "\n",
    "col_types = [str, float, str, str, float, int]\n",
    "with open('stocks.csv') as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    headers = next(f_csv)\n",
    "    for row in f_csv:\n",
    "        # Apply conversions to the row items\n",
    "        row = tuple(convert(value) for convert, value in zip(col_types, row))\n",
    "        # ...\n",
    "\n",
    "# Example showing converting selected fields of dictionaries:\n",
    "\n",
    "print('Reading as dicts with type conversion')\n",
    "field_types = [ ('Price', float),\n",
    "                ('Change', float),\n",
    "                ('Volume', int) ]\n",
    "\n",
    "with open('stocks.csv') as f:\n",
    "    for row in csv.DictReader(f):\n",
    "        row.update((key, conversion(row[key])) for key, conversion in field_types)\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1f5cddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Symbol', 'Price', 'Date', 'Time', 'Change', 'Volume\\n']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f102d259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversions are very tricky IRL, because there will be:\n",
    "\n",
    "# missing values\n",
    "# corrupted data\n",
    "# other issues that break type conversions\n",
    "\n",
    "# YOU WILL NEED to add suitable exception handling\n",
    "\n",
    "# For data analysis AND statistics, look at the package called\n",
    "# Panda\n",
    "\n",
    "# convenient functions from within this package include:\n",
    "\n",
    "pandas.read_csv()\n",
    "\n",
    "# which loads CSV data into a DataFrame object\n",
    "# DataFrame objects allow for:\n",
    "# summary stats\n",
    "# filter the data\n",
    "# perform other high-level operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d98f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2\n",
    "# Reading and Writing JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae5093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b40f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8f2aab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e058b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d2ae74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2462c59",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Now with a namedtuple for each line of stock data,\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# these can be accessed using column headers such as:\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mrow\u001b[49m\u001b[38;5;241m.\u001b[39mSymbol\n\u001b[1;32m      4\u001b[0m row\u001b[38;5;241m.\u001b[39mChange\n",
      "\u001b[0;31mNameError\u001b[0m: name 'row' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b13f0fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/tsinks'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dde1a635",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (3053100435.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [6]\u001b[0;36m\u001b[0m\n\u001b[0;31m    f.write('Symbol,Price,Date,Time,Change,Volume\u001b[0m\n\u001b[0m                                                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a0b602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
